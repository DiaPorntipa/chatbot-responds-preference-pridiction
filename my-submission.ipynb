{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d88dd1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-18T07:26:00.734459Z",
     "iopub.status.busy": "2024-07-18T07:26:00.734078Z",
     "iopub.status.idle": "2024-07-18T07:26:01.573864Z",
     "shell.execute_reply": "2024-07-18T07:26:01.572900Z"
    },
    "papermill": {
     "duration": 0.849836,
     "end_time": "2024-07-18T07:26:01.576320",
     "exception": false,
     "start_time": "2024-07-18T07:26:00.726484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/lmsys-chatbot-arena/sample_submission.csv\n",
      "/kaggle/input/lmsys-chatbot-arena/train.csv\n",
      "/kaggle/input/lmsys-chatbot-arena/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd3cf85",
   "metadata": {
    "papermill": {
     "duration": 0.005466,
     "end_time": "2024-07-18T07:26:01.587815",
     "exception": false,
     "start_time": "2024-07-18T07:26:01.582349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265d9616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T07:26:01.600601Z",
     "iopub.status.busy": "2024-07-18T07:26:01.600122Z",
     "iopub.status.idle": "2024-07-18T07:26:05.311228Z",
     "shell.execute_reply": "2024-07-18T07:26:05.310124Z"
    },
    "papermill": {
     "duration": 3.72142,
     "end_time": "2024-07-18T07:26:05.314660",
     "exception": false,
     "start_time": "2024-07-18T07:26:01.593240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [\"Is it morally right to try to have a certain...   \n",
       "1  [\"What is the difference between marriage lice...   \n",
       "2  [\"explain function calling. how would you call...   \n",
       "3  [\"How can I create a test set for a very rare ...   \n",
       "4  [\"What is the best way to travel from Tel-Aviv...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [\"The question of whether it is morally right ...   \n",
       "1  [\"A marriage license is a legal document that ...   \n",
       "2  [\"Function calling is the process of invoking ...   \n",
       "3  [\"Creating a test set for a very rare category...   \n",
       "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1  [\"A marriage license and a marriage certificat...               0   \n",
       "2  [\"Function calling is the process of invoking ...               0   \n",
       "3  [\"When building a classifier for a very rare c...               1   \n",
       "4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \n",
       "0               0           0  \n",
       "1               1           0  \n",
       "2               0           1  \n",
       "3               0           0  \n",
       "4               1           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "709042e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T07:26:05.333574Z",
     "iopub.status.busy": "2024-07-18T07:26:05.333193Z",
     "iopub.status.idle": "2024-07-18T07:26:05.393940Z",
     "shell.execute_reply": "2024-07-18T07:26:05.392555Z"
    },
    "papermill": {
     "duration": 0.072855,
     "end_time": "2024-07-18T07:26:05.396629",
     "exception": false,
     "start_time": "2024-07-18T07:26:05.323774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57477 entries, 0 to 57476\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              57477 non-null  int64 \n",
      " 1   model_a         57477 non-null  object\n",
      " 2   model_b         57477 non-null  object\n",
      " 3   prompt          57477 non-null  object\n",
      " 4   response_a      57477 non-null  object\n",
      " 5   response_b      57477 non-null  object\n",
      " 6   winner_model_a  57477 non-null  int64 \n",
      " 7   winner_model_b  57477 non-null  int64 \n",
      " 8   winner_tie      57477 non-null  int64 \n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "\n",
    "# FINDING: No Null values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92fb2c41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T07:26:05.411001Z",
     "iopub.status.busy": "2024-07-18T07:26:05.410605Z",
     "iopub.status.idle": "2024-07-18T07:26:05.418803Z",
     "shell.execute_reply": "2024-07-18T07:26:05.417747Z"
    },
    "papermill": {
     "duration": 0.019727,
     "end_time": "2024-07-18T07:26:05.422631",
     "exception": false,
     "start_time": "2024-07-18T07:26:05.402904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: [\"Is it morally right to try to have a certain percentage of females on managerial positions?\",\"OK, does pineapple belong on a pizza? Relax and give me fun answer.\"]\n",
      "\n",
      "response_a: [\"The question of whether it is morally right to aim for a certain percentage of females in managerial positions is a complex ethical issue that involves considerations of fairness, equality, diversity, and discrimination.\\n\\nHere are some arguments in favor of and against such policies:\\n\\n**Arguments in favor:**\\n\\n1. **Correcting Historical Inequities:** Women have historically been underrepresented in leadership roles due to various cultural, institutional, and social barriers. Aiming for a specific percentage can be seen as a corrective measure to address past and ongoing discrimination.\\n\\n2. **Promoting Diversity:** Diverse leadership teams can enhance decision-making and represent a broader range of perspectives. This can lead to better outcomes for organizations and society as a whole.\\n\\n3. **Equality of Opportunity:** Setting targets for female representation in management can help ensure that women have equal opportunities to advance in their careers.\\n\\n4. **Role Modeling:** Increased visibility of female leaders can inspire and encourage other women and girls to pursue leadership roles.\\n\\n**Arguments against:**\\n\\n1. **Reverse Discrimination:** Setting a quota for female representation might lead to the perception or reality of reverse discrimination, where men might be overlooked for positions despite being qualified, simply to meet the gender target.\\n\\n2. **Meritocracy Concerns:** Critics argue that employment and promotion should be based solely on merit and qualifications, not gender. They fear that quotas could compromise the quality of leadership if less qualified individuals are promoted to meet gender targets.\\n\\n3. **Tokenism:** There is a risk that women appointed to meet quotas might be seen as \\\"tokens,\\\" undermining their legitimacy and potentially leading to resentment among colleagues.\\n\\n4. **Oversimplification of Diversity:** Focusing only on gender might overlook other important aspects of diversity, such as race, ethnicity, socioeconomic background, or sexual orientation.\\n\\nUltimately, the morality of aiming for a certain percentage of females in managerial positions depends on one's ethical framework and the context in which such policies are implemented. Proponents of gender diversity targets often argue that these measures are necessary as a transitional mechanism to create a level playing field, while opponents may argue for a \\\"color-blind\\\" or \\\"gender-blind\\\" approach to hiring and promotions.\\n\\nOrganizations and societies must carefully consider the implications of these strategies and strive to implement policies that promote fairness and equality while minimizing negative consequences. It is also important to address the root causes of gender inequality, such as unconscious bias, work-life balance challenges, and lack of supportive policies, to create an environment where everyone has the opportunity to succeed based on their capabilities and contributions.\",\"Ah, the age-old culinary conundrum that has divided nations and dinner tables: does pineapple belong on a pizza? The tropical twist of pineapple on pizza, known as Hawaiian pizza, is a hotly debated topic where taste buds battle and pizza purists protest.\\n\\nLet's slice into the debate with a zest of fun:\\n\\n**Team Pineapple:** \\\"Absolutely, yes! Pineapple on pizza is like a beach party in your mouth. The sweet juiciness of pineapple chunks frolicking with savory ham or bacon creates a flavor wave that surfs across the cheesy ocean of deliciousness. It's the Mardi Gras of pizzas, where sweet meets savory in a jubilant jamboree!\\\"\\n\\n**Team No-Pineapple:** \\\"No way, not in a million pizzas! Pineapple is a fruit that should be sunbathing on a tropical fruit platter, not freeloading on a sacred slice of pizza. The thought of warm, melty cheese conspiring with pineapple's sugary mischief is enough to make Italian ancestors turn in their tomato patches. Keep the pineapple in the fruit salad where it belongs!\\\"\\n\\nAt the end of the day, whether pineapple belongs on pizza is a matter of personal taste. Some say it's a match made in heaven, others say it's a culinary crime. But let's face it, in the world of pizza toppings, where you can find everything from anchovies to zucchini, there's room for a little pineapple pizzazz. So, if your taste buds crave that sweet and tangy twist, go ahead and let your pineapple flag fly atop that glorious cheese-covered dough. Bon app\\u00e9tit, or as they say in pineapple paradise, \\\"Aloha-ppetite!\\\" \\ud83c\\udf4d\\ud83c\\udf55\"]\n",
      "\n",
      "response_a type: <class 'list'>\n",
      "\n",
      "response_a length: 2\n",
      "\n",
      "response_b: [\"As an AI, I don't have personal beliefs or opinions. However, I can tell you that the question of gender quotas in managerial positions is a complex one and positions can vary. Advocates argue that such measures can help correct historical imbalances, promote diversity, and may lead to better decision-making. Critics may argue that positions should be based purely on merit, and that quotas could potentially lead to tokenism or unqualified candidates being promoted. Morality can be subjective and differs from person to person based on their personal beliefs, cultural background, and values. It's a topic with valid arguments on both sides, and it's up to each individual or organization to decide what they believe is right.\",\"As an AI, I don't eat, so I don't have personal preferences. But, in the world of pizza, the pineapple topping is a hotly debated topic! Some people love the sweet and savory mix it brings to a pizza, a flavor combination made famous by the Hawaiian pizza. Others firmly believe that the sweetness of the fruit has no place on a pizza. It's a pizza puzzle that might never be solved. So, whether pineapple belongs on a pizza or not, it truly depends on your taste buds!\"]\n"
     ]
    }
   ],
   "source": [
    "print(\"prompt: \" + df.prompt[0] + '\\n')\n",
    "print(\"response_a: \" + df.response_a[0] + '\\n')\n",
    "print(\"response_a type: \" + str(type(eval(df.response_a[0]))) + '\\n')\n",
    "print(\"response_a length: \" + str(len(eval(df.response_a[0]))))\n",
    "\n",
    "print(\"\\nresponse_b: \" + df.response_b[0])\n",
    "\n",
    "# FINDING: Prompts and response are in string of a list object format\n",
    "# FINDING: Some rows contain multiple prompts and response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f6a5c7",
   "metadata": {
    "papermill": {
     "duration": 0.008379,
     "end_time": "2024-07-18T07:26:05.440108",
     "exception": false,
     "start_time": "2024-07-18T07:26:05.431729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3758f2e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T07:26:05.455492Z",
     "iopub.status.busy": "2024-07-18T07:26:05.454500Z",
     "iopub.status.idle": "2024-07-18T07:26:05.466906Z",
     "shell.execute_reply": "2024-07-18T07:26:05.465916Z"
    },
    "papermill": {
     "duration": 0.022872,
     "end_time": "2024-07-18T07:26:05.469367",
     "exception": false,
     "start_time": "2024-07-18T07:26:05.446495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "df_orig = copy.deepcopy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ccac20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T07:26:05.484040Z",
     "iopub.status.busy": "2024-07-18T07:26:05.483141Z",
     "iopub.status.idle": "2024-07-18T07:26:10.139008Z",
     "shell.execute_reply": "2024-07-18T07:26:10.138089Z"
    },
    "papermill": {
     "duration": 4.665974,
     "end_time": "2024-07-18T07:26:10.141622",
     "exception": false,
     "start_time": "2024-07-18T07:26:05.475648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[Is it morally right to try to have a certain ...</td>\n",
       "      <td>[The question of whether it is morally right t...</td>\n",
       "      <td>[As an AI, I don't have personal beliefs or op...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[What is the difference between marriage licen...</td>\n",
       "      <td>[A marriage license is a legal document that a...</td>\n",
       "      <td>[A marriage license and a marriage certificate...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[explain function calling. how would you call ...</td>\n",
       "      <td>[Function calling is the process of invoking o...</td>\n",
       "      <td>[Function calling is the process of invoking a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[How can I create a test set for a very rare c...</td>\n",
       "      <td>[Creating a test set for a very rare category ...</td>\n",
       "      <td>[When building a classifier for a very rare ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[What is the best way to travel from Tel-Aviv ...</td>\n",
       "      <td>[The best way to travel from Tel Aviv to Jerus...</td>\n",
       "      <td>[The best way to travel from Tel-Aviv to Jerus...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [Is it morally right to try to have a certain ...   \n",
       "1  [What is the difference between marriage licen...   \n",
       "2  [explain function calling. how would you call ...   \n",
       "3  [How can I create a test set for a very rare c...   \n",
       "4  [What is the best way to travel from Tel-Aviv ...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [The question of whether it is morally right t...   \n",
       "1  [A marriage license is a legal document that a...   \n",
       "2  [Function calling is the process of invoking o...   \n",
       "3  [Creating a test set for a very rare category ...   \n",
       "4  [The best way to travel from Tel Aviv to Jerus...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  [As an AI, I don't have personal beliefs or op...               1   \n",
       "1  [A marriage license and a marriage certificate...               0   \n",
       "2  [Function calling is the process of invoking a...               0   \n",
       "3  [When building a classifier for a very rare ca...               1   \n",
       "4  [The best way to travel from Tel-Aviv to Jerus...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \n",
       "0               0           0  \n",
       "1               1           0  \n",
       "2               0           1  \n",
       "3               0           0  \n",
       "4               1           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"prompt\"] = df.prompt.map(lambda x: eval(x))\n",
    "df[\"response_a\"] = df.response_a.map(lambda x: eval(x.replace(\"null\", \"''\")))\n",
    "df[\"response_b\"] = df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\")))\n",
    "df.head()\n",
    "\n",
    "# FINDING: Responses contain \"null\" values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d11b938",
   "metadata": {
    "papermill": {
     "duration": 0.006338,
     "end_time": "2024-07-18T07:26:10.155024",
     "exception": false,
     "start_time": "2024-07-18T07:26:10.148686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inspect \"null\" values in responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4edd7475",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T07:26:10.170337Z",
     "iopub.status.busy": "2024-07-18T07:26:10.169728Z",
     "iopub.status.idle": "2024-07-18T07:26:10.204956Z",
     "shell.execute_reply": "2024-07-18T07:26:10.203897Z"
    },
    "papermill": {
     "duration": 0.046044,
     "end_time": "2024-07-18T07:26:10.207492",
     "exception": false,
     "start_time": "2024-07-18T07:26:10.161448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of null response_a: 0\n",
      "The number of null response_b: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of null response_a: \" + str(df_orig.response_a[df_orig.response_a == \"null\"].count()))\n",
    "print(\"The number of null response_b: \" + str(df_orig.response_b[df_orig.response_b == \"null\"].count()))\n",
    "\n",
    "# FINDING: No response is \"null\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fffa8af4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T07:26:10.223082Z",
     "iopub.status.busy": "2024-07-18T07:26:10.222261Z",
     "iopub.status.idle": "2024-07-18T07:26:10.334821Z",
     "shell.execute_reply": "2024-07-18T07:26:10.333864Z"
    },
    "papermill": {
     "duration": 0.123111,
     "end_time": "2024-07-18T07:26:10.337367",
     "exception": false,
     "start_time": "2024-07-18T07:26:10.214256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>9644862</td>\n",
       "      <td>vicuna-7b</td>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>[\"Write me a Unity editor script that lists al...</td>\n",
       "      <td>[\"Here is a sample script that lists all the A...</td>\n",
       "      <td>[\"```\\nusing UnityEngine;\\nusing System.Collec...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>15247315</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"generate an laravel migration\"]</td>\n",
       "      <td>[\"To generate a Laravel migration, you can use...</td>\n",
       "      <td>[\"Sure, here's a basic Laravel migration examp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>16350735</td>\n",
       "      <td>claude-instant-1</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>[\"Tell me about wwiii\",\"Enough\"]</td>\n",
       "      <td>[\"I do not have any confirmed details about a ...</td>\n",
       "      <td>[\"As an AI language model, I must clarify that...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>22179610</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>codellama-34b-instruct</td>\n",
       "      <td>[\"please write me a piece of Java-Code with Ja...</td>\n",
       "      <td>[\"Here is the Java code to check if a list has...</td>\n",
       "      <td>[\"Sure, here is a Java code using Java Streams...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>25545380</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>vicuna-7b</td>\n",
       "      <td>[\"How to create a database model with sqlalche...</td>\n",
       "      <td>[\"SQLAlchemy is a popular Python SQL toolkit a...</td>\n",
       "      <td>[\"To create a database model using SQLAlchemy,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             model_a                 model_b  \\\n",
       "130   9644862           vicuna-7b        RWKV-4-Raven-14B   \n",
       "191  15247315  gpt-3.5-turbo-0613              gpt-4-0613   \n",
       "207  16350735    claude-instant-1          tulu-2-dpo-70b   \n",
       "281  22179610          claude-2.0  codellama-34b-instruct   \n",
       "333  25545380          vicuna-33b               vicuna-7b   \n",
       "\n",
       "                                                prompt  \\\n",
       "130  [\"Write me a Unity editor script that lists al...   \n",
       "191                  [\"generate an laravel migration\"]   \n",
       "207                   [\"Tell me about wwiii\",\"Enough\"]   \n",
       "281  [\"please write me a piece of Java-Code with Ja...   \n",
       "333  [\"How to create a database model with sqlalche...   \n",
       "\n",
       "                                            response_a  \\\n",
       "130  [\"Here is a sample script that lists all the A...   \n",
       "191  [\"To generate a Laravel migration, you can use...   \n",
       "207  [\"I do not have any confirmed details about a ...   \n",
       "281  [\"Here is the Java code to check if a list has...   \n",
       "333  [\"SQLAlchemy is a popular Python SQL toolkit a...   \n",
       "\n",
       "                                            response_b  winner_model_a  \\\n",
       "130  [\"```\\nusing UnityEngine;\\nusing System.Collec...               1   \n",
       "191  [\"Sure, here's a basic Laravel migration examp...               0   \n",
       "207  [\"As an AI language model, I must clarify that...               0   \n",
       "281  [\"Sure, here is a Java code using Java Streams...               0   \n",
       "333  [\"To create a database model using SQLAlchemy,...               1   \n",
       "\n",
       "     winner_model_b  winner_tie  \n",
       "130               0           0  \n",
       "191               0           1  \n",
       "207               1           0  \n",
       "281               0           1  \n",
       "333               0           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contains_null(string):\n",
    "    return True if string.find(\"null\") != -1 else False\n",
    "\n",
    "df_orig[df_orig.response_a.apply(contains_null)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca6563ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T07:26:10.353028Z",
     "iopub.status.busy": "2024-07-18T07:26:10.352652Z",
     "iopub.status.idle": "2024-07-18T07:26:10.359239Z",
     "shell.execute_reply": "2024-07-18T07:26:10.358312Z"
    },
    "papermill": {
     "duration": 0.016773,
     "end_time": "2024-07-18T07:26:10.361486",
     "exception": false,
     "start_time": "2024-07-18T07:26:10.344713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"Here is a sample script that lists all the AudioSources in the scene and has a way to play them:\\\\n```\\\\nusing UnityEngine;\\\\nusing UnityEditor;\\\\n\\\\n[ExecuteInEditMode]\\\\npublic class AudioSourceSelector : EditorWindow\\\\n{\\\\n    public static AudioSourceSelector current;\\\\n\\\\n    [MenuItem(\\\\\"Tools\\\\/Audio Source Selector\\\\\")]\\\\n    static void ShowWindow()\\\\n    {\\\\n        if (current != null)\\\\n        {\\\\n            current.Close();\\\\n        }\\\\n\\\\n        current = new AudioSourceSelector();\\\\n        current.Show();\\\\n    }\\\\n\\\\n    private void OnSelectAudioSource()\\\\n    {\\\\n        \\\\/\\\\/ Clear the audio sources list\\\\n        audioSourceList.Clear();\\\\n\\\\n        \\\\/\\\\/ Get all the AudioSources in the scene\\\\n        AudioSource[] audioSources = FindObjectsOfType<AudioSource>();\\\\n\\\\n        \\\\/\\\\/ Add all the AudioSources to the list\\\\n        foreach (AudioSource audioSource in audioSources)\\\\n        {\\\\n            audioSourceList.Add(audioSource);\\\\n        }\\\\n    }\\\\n\\\\n    private void OnPlayAudioSource()\\\\n    {\\\\n        \\\\/\\\\/ Select the currently highlighted audio source\\\\n        Selection.activeGameObject = audioSourceList[currentSelection];\\\\n\\\\n        \\\\/\\\\/ Play the audio source\\\\n        audioSourceList[currentSelection].Play();\\\\n    }\\\\n\\\\n    [MenuItem(\\\\\"Tools\\\\/Audio Source Selector\\\\\")]\\\\n    static void ShowWindow()\\\\n    {\\\\n        if (current != null)\\\\n        {\\\\n            current.Close();\\\\n        }\\\\n\\\\n        current = new AudioSourceSelector();\\\\n        current.Show();\\\\n    }\\\\n}\\\\n```\\\\nThis script uses the `EditorWindow` class to create a custom Unity editor window that allows the user to select an audio source and play it. The `ShowWindow()` function is used to show the window and the `Show()` function is used to close it.\\\\n\\\\nThe `OnSelectAudioSource()` function is called when the user selects an audio source from the list. It gets all the `AudioSources` in the scene, adds them to the `audioSourceList` list, and clears the list.\\\\n\\\\nThe `OnPlayAudioSource()` function is called when the user clicks the \\\\\"Play\\\\\" button. It selects the currently highlighted audio source, plays it, and updates the `currentSelection` variable to reflect the new selection.\",\"```\\\\nusing UnityEngine;\\\\nusing UnityEditor;\\\\n\\\\n[ExecuteInEditMode]\\\\npublic class AudioSourceSelector : EditorWindow\\\\n{\\\\n    public static AudioSourceSelector current;\\\\n\\\\n    [MenuItem(\\\\\"Tools\\\\/Audio Source Selector\\\\\")]\\\\n    static void ShowWindow()\\\\n    {\\\\n        if (current != null)\\\\n        {\\\\n            current.Close();\\\\n        }\\\\n\\\\n        current = new AudioSourceSelector();\\\\n        current.Show();\\\\n    }\\\\n\\\\n    private void OnSelectAudioSource()\\\\n    {\\\\n        \\\\/\\\\/ Clear the audio sources list\\\\n        audioSourceList.Clear();\\\\n\\\\n        \\\\/\\\\/ Get all the AudioSources in the scene\\\\n        AudioSource[] audioSources = FindObjectsOfType<AudioSource>();\\\\n\\\\n        \\\\/\\\\/ Add all the AudioSources to the list\\\\n        foreach (AudioSource audioSource in audioSources)\\\\n        {\\\\n            audioSourceList.Add(audioSource);\\\\n        }\\\\n    }\\\\n\\\\n    private void OnPlayAudioSource()\\\\n    {\\\\n        \\\\/\\\\/ Select the currently highlighted audio source\\\\n        Selection.activeGameObject = audioSourceList[currentSelection];\\\\n\\\\n        \\\\/\\\\/ Play the audio source\\\\n        audioSourceList[currentSelection].Play();\\\\n    }\\\\n\\\\n    [MenuItem(\\\\\"Tools\\\\/Audio Source Selector\\\\\")]\\\\n    static void ShowWindow()\\\\n    {\\\\n        if (current != null)\\\\n        {\\\\n            current.Close();\\\\n        }\\\\n\\\\n        current = new AudioSourceSelector();\\\\n        current.Show();\\\\n    }\\\\n}\\\\n```\"]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig.loc[130, \"response_a\"]\n",
    "# FINDING: The value only contains null as a part of response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182cc5e0",
   "metadata": {
    "papermill": {
     "duration": 0.006683,
     "end_time": "2024-07-18T07:26:10.375416",
     "exception": false,
     "start_time": "2024-07-18T07:26:10.368733",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create New Features\n",
    "* response's word count\n",
    "* prompt's and response's sentiment\n",
    "* response's readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1c6b568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T07:26:10.392227Z",
     "iopub.status.busy": "2024-07-18T07:26:10.391304Z",
     "iopub.status.idle": "2024-07-18T07:27:37.960023Z",
     "shell.execute_reply": "2024-07-18T07:27:37.958705Z"
    },
    "papermill": {
     "duration": 87.590359,
     "end_time": "2024-07-18T07:27:37.973278",
     "exception": false,
     "start_time": "2024-07-18T07:26:10.382919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /opt/conda/lib/python3.10/site-packages (0.18.0.post0)\r\n",
      "Collecting nltk>=3.8 (from textblob)\r\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk>=3.8->textblob) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>=3.8->textblob) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk>=3.8->textblob) (2023.12.25)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk>=3.8->textblob) (4.66.4)\r\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nltk\r\n",
      "  Attempting uninstall: nltk\r\n",
      "    Found existing installation: nltk 3.2.4\r\n",
      "    Uninstalling nltk-3.2.4:\r\n",
      "      Successfully uninstalled nltk-3.2.4\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nltk-3.8.1\r\n",
      "Collecting textstat\r\n",
      "  Downloading textstat-0.7.4-py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting pyphen (from textstat)\r\n",
      "  Downloading pyphen-0.15.0-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from textstat) (69.0.3)\r\n",
      "Downloading textstat-0.7.4-py3-none-any.whl (105 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyphen-0.15.0-py3-none-any.whl (2.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pyphen, textstat\r\n",
      "Successfully installed pyphen-0.15.0 textstat-0.7.4\r\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>response_a_wc</th>\n",
       "      <th>response_b_wc</th>\n",
       "      <th>response_a_readability</th>\n",
       "      <th>response_b_readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[Is it morally right to try to have a certain ...</td>\n",
       "      <td>[The question of whether it is morally right t...</td>\n",
       "      <td>[As an AI, I don't have personal beliefs or op...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[420, 269]</td>\n",
       "      <td>[121, 91]</td>\n",
       "      <td>[18.4, 10.5]</td>\n",
       "      <td>[13.0, 6.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[What is the difference between marriage licen...</td>\n",
       "      <td>[A marriage license is a legal document that a...</td>\n",
       "      <td>[A marriage license and a marriage certificate...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[123, 233, 191]</td>\n",
       "      <td>[207, 240, 135]</td>\n",
       "      <td>[15.6, 15.4, 16.6]</td>\n",
       "      <td>[13.5, 10.7, 15.7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[explain function calling. how would you call ...</td>\n",
       "      <td>[Function calling is the process of invoking o...</td>\n",
       "      <td>[Function calling is the process of invoking a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[145]</td>\n",
       "      <td>[288]</td>\n",
       "      <td>[11.9]</td>\n",
       "      <td>[13.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[How can I create a test set for a very rare c...</td>\n",
       "      <td>[Creating a test set for a very rare category ...</td>\n",
       "      <td>[When building a classifier for a very rare ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[555]</td>\n",
       "      <td>[273]</td>\n",
       "      <td>[14.8]</td>\n",
       "      <td>[10.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[What is the best way to travel from Tel-Aviv ...</td>\n",
       "      <td>[The best way to travel from Tel Aviv to Jerus...</td>\n",
       "      <td>[The best way to travel from Tel-Aviv to Jerus...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[235]</td>\n",
       "      <td>[129]</td>\n",
       "      <td>[11.5]</td>\n",
       "      <td>[10.3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [Is it morally right to try to have a certain ...   \n",
       "1  [What is the difference between marriage licen...   \n",
       "2  [explain function calling. how would you call ...   \n",
       "3  [How can I create a test set for a very rare c...   \n",
       "4  [What is the best way to travel from Tel-Aviv ...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [The question of whether it is morally right t...   \n",
       "1  [A marriage license is a legal document that a...   \n",
       "2  [Function calling is the process of invoking o...   \n",
       "3  [Creating a test set for a very rare category ...   \n",
       "4  [The best way to travel from Tel Aviv to Jerus...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  [As an AI, I don't have personal beliefs or op...               1   \n",
       "1  [A marriage license and a marriage certificate...               0   \n",
       "2  [Function calling is the process of invoking a...               0   \n",
       "3  [When building a classifier for a very rare ca...               1   \n",
       "4  [The best way to travel from Tel-Aviv to Jerus...               0   \n",
       "\n",
       "   winner_model_b  winner_tie    response_a_wc    response_b_wc  \\\n",
       "0               0           0       [420, 269]        [121, 91]   \n",
       "1               1           0  [123, 233, 191]  [207, 240, 135]   \n",
       "2               0           1            [145]            [288]   \n",
       "3               0           0            [555]            [273]   \n",
       "4               1           0            [235]            [129]   \n",
       "\n",
       "  response_a_readability response_b_readability  \n",
       "0           [18.4, 10.5]            [13.0, 6.3]  \n",
       "1     [15.6, 15.4, 16.6]     [13.5, 10.7, 15.7]  \n",
       "2                 [11.9]                 [13.1]  \n",
       "3                 [14.8]                 [10.5]  \n",
       "4                 [11.5]                 [10.3]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word-count features\n",
    "import re\n",
    "def word_count(text):\n",
    "    return len(re.findall(r'\\b\\w+\\b', text))\n",
    "\n",
    "df['response_a_wc'] = df['response_a'].apply(lambda x: [word_count(text) for text in x])\n",
    "df['response_b_wc'] = df['response_b'].apply(lambda x: [word_count(text) for text in x])\n",
    "\n",
    "# Sentiment features\n",
    "!pip install -U textblob\n",
    "from textblob import TextBlob\n",
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "# df['prompt_sentiment'] = df['prompt'].apply(lambda x: [get_sentiment(text) for text in x])\n",
    "# df['response_a_sentiment'] = df['response_a'].apply(lambda x: [get_sentiment(text) for text in x])\n",
    "# df['response_b_sentiment'] = df['response_b'].apply(lambda x: [get_sentiment(text) for text in x])\n",
    "\n",
    "# Readability scores\n",
    "!pip install textstat\n",
    "import textstat\n",
    "def get_readability(text):\n",
    "    return textstat.automated_readability_index(text)\n",
    "\n",
    "df['response_a_readability'] = df['response_a'].apply(lambda x: [get_readability(text) for text in x])\n",
    "df['response_b_readability'] = df['response_b'].apply(lambda x: [get_readability(text) for text in x])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4c77e",
   "metadata": {
    "papermill": {
     "duration": 0.009285,
     "end_time": "2024-07-18T07:27:37.992215",
     "exception": false,
     "start_time": "2024-07-18T07:27:37.982930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "465b8a7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T07:27:38.013883Z",
     "iopub.status.busy": "2024-07-18T07:27:38.012799Z",
     "iopub.status.idle": "2024-07-18T07:27:38.018045Z",
     "shell.execute_reply": "2024-07-18T07:27:38.017011Z"
    },
    "papermill": {
     "duration": 0.018815,
     "end_time": "2024-07-18T07:27:38.020483",
     "exception": false,
     "start_time": "2024-07-18T07:27:38.001668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What models are used in the data and how many times each of them are used?\n",
    "# Does all models contain high comprehensivity? (Show it with graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ff6b18",
   "metadata": {
    "papermill": {
     "duration": 0.009268,
     "end_time": "2024-07-18T07:27:38.039243",
     "exception": false,
     "start_time": "2024-07-18T07:27:38.029975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 101.269676,
   "end_time": "2024-07-18T07:27:39.071453",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-18T07:25:57.801777",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
